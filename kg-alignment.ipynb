{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the project called Entity Alignment using Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the script for the dataset processing. We are going to map the entity ids to the entity name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (4500, 3)\n",
      "\n",
      "First few rows:\n",
      "   index                                         candidates  num_candidates\n",
      "0      0  [10500, 33775, 36175, 17181, 20105, 32176, 117...              20\n",
      "1      1  [10501, 36449, 11420, 18572, 33228, 15363, 333...              20\n",
      "2      2  [20759, 10502, 18084, 16541, 13414, 15062, 332...              20\n",
      "3      3  [10503, 15732, 31027, 19403, 38929, 37146, 176...              20\n",
      "4      4  [33507, 15190, 10504, 19425, 38842, 37861, 324...              20\n",
      "\n",
      "DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4500 entries, 0 to 4499\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   index           4500 non-null   int64 \n",
      " 1   candidates      4500 non-null   object\n",
      " 2   num_candidates  4500 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 105.6+ KB\n",
      "None\n",
      "\n",
      "Sample candidates for first entity:\n",
      "Entity 0: [10500, 33775, 36175, 17181, 20105, 32176, 11787, 38085, 37257, 33904]...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the train.cand_list.20 file as a pandas DataFrame\n",
    "file_path = \"data/DBP15K/torch_geometric_cache/raw/fr_en/train.cand_list.20\"\n",
    "\n",
    "# Read the file and parse it\n",
    "data = []\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            # Split by ': ' to separate index from candidate list\n",
    "            parts = line.split(': ', 1)\n",
    "            if len(parts) == 2:\n",
    "                index = int(parts[0])\n",
    "                candidates = [int(x) for x in parts[1].split()]\n",
    "                data.append({'index': index, 'candidates': candidates, 'num_candidates': len(candidates)})\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataFrame info:\")\n",
    "print(df.info())\n",
    "print(f\"\\nSample candidates for first entity:\")\n",
    "print(f\"Entity {df.iloc[0]['index']}: {df.iloc[0]['candidates'][:10]}...\")  # Show first 10 candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>candidates</th>\n",
       "      <th>num_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[10500, 33775, 36175, 17181, 20105, 32176, 117...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[10501, 36449, 11420, 18572, 33228, 15363, 333...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[20759, 10502, 18084, 16541, 13414, 15062, 332...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[10503, 15732, 31027, 19403, 38929, 37146, 176...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[33507, 15190, 10504, 19425, 38842, 37861, 324...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                         candidates  num_candidates\n",
       "0      0  [10500, 33775, 36175, 17181, 20105, 32176, 117...              20\n",
       "1      1  [10501, 36449, 11420, 18572, 33228, 15363, 333...              20\n",
       "2      2  [20759, 10502, 18084, 16541, 13414, 15062, 332...              20\n",
       "3      3  [10503, 15732, 31027, 19403, 38929, 37146, 176...              20\n",
       "4      4  [33507, 15190, 10504, 19425, 38842, 37861, 324...              20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading entity mappings...\n",
      "Loaded 19661 entities from KG1 (French)\n",
      "Loaded 19993 entities from KG2 (English)\n",
      "\n",
      "Sample mappings from KG1:\n",
      "  ID 0: Saint-Joseph-de-Coleraine (http://fr.dbpedia.org/resource/Saint-Joseph-de-Coleraine)\n",
      "  ID 1: Self_Portrait (http://fr.dbpedia.org/resource/Self_Portrait)\n",
      "  ID 2: Alliance_des_libéraux_et_des_démocrates_pour_l'Europe (http://fr.dbpedia.org/resource/Alliance_des_libéraux_et_des_démocrates_pour_l'Europe)\n",
      "\n",
      "Sample mappings from KG2:\n",
      "  ID 10500: Saint-Joseph-de-Coleraine,_Quebec (http://dbpedia.org/resource/Saint-Joseph-de-Coleraine,_Quebec)\n",
      "  ID 10501: Self_Portrait_(Bob_Dylan_album) (http://dbpedia.org/resource/Self_Portrait_(Bob_Dylan_album))\n",
      "  ID 10502: Alliance_of_Liberals_and_Democrats_for_Europe_Party (http://dbpedia.org/resource/Alliance_of_Liberals_and_Democrats_for_Europe_Party)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Create processed_data directory if it doesn't exist\n",
    "os.makedirs('processed_data', exist_ok=True)\n",
    "\n",
    "def load_entity_mappings(file_path):\n",
    "    \"\"\"Load entity ID to URI mappings from file\"\"\"\n",
    "    mappings = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split('\\t', 1)\n",
    "                if len(parts) == 2:\n",
    "                    entity_id = int(parts[0])\n",
    "                    entity_uri = parts[1]\n",
    "                    # Extract entity name from URI (last part after /)\n",
    "                    entity_name = entity_uri.split('/')[-1]\n",
    "                    mappings[entity_id] = {\n",
    "                        'name': entity_name,\n",
    "                        'uri': entity_uri\n",
    "                    }\n",
    "    return mappings\n",
    "\n",
    "# Load entity mappings\n",
    "print(\"Loading entity mappings...\")\n",
    "kg1_mappings = load_entity_mappings(\"data/DBP15K/torch_geometric_cache/raw/fr_en/ent_ids_1\")  # French entities\n",
    "kg2_mappings = load_entity_mappings(\"data/DBP15K/torch_geometric_cache/raw/fr_en/ent_ids_2\")  # English entities\n",
    "\n",
    "print(f\"Loaded {len(kg1_mappings)} entities from KG1 (French)\")\n",
    "print(f\"Loaded {len(kg2_mappings)} entities from KG2 (English)\")\n",
    "\n",
    "# Check first few mappings\n",
    "print(\"\\nSample mappings from KG1:\")\n",
    "for i, (k, v) in enumerate(list(kg1_mappings.items())[:3]):\n",
    "    print(f\"  ID {k}: {v['name']} ({v['uri']})\")\n",
    "\n",
    "print(\"\\nSample mappings from KG2:\")\n",
    "for i, (k, v) in enumerate(list(kg2_mappings.items())[:3]):\n",
    "    print(f\"  ID {k}: {v['name']} ({v['uri']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced dataframe with entity names and URIs...\n",
      "Enhanced DataFrame shape: (4500, 6)\n",
      "\n",
      "First few rows of enhanced DataFrame:\n",
      "                                          index_name  \\\n",
      "0                          Saint-Joseph-de-Coleraine   \n",
      "1                                      Self_Portrait   \n",
      "2  Alliance_des_libéraux_et_des_démocrates_pour_l...   \n",
      "3                                             Wallon   \n",
      "4                                            Android   \n",
      "\n",
      "                                           index_uri  index_id index_language  \\\n",
      "0  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "1       http://fr.dbpedia.org/resource/Self_Portrait         1         French   \n",
      "2  http://fr.dbpedia.org/resource/Alliance_des_li...         2         French   \n",
      "3              http://fr.dbpedia.org/resource/Wallon         3         French   \n",
      "4             http://fr.dbpedia.org/resource/Android         4         French   \n",
      "\n",
      "   num_candidates  \n",
      "0              20  \n",
      "1              20  \n",
      "2              20  \n",
      "3              20  \n",
      "4              20  \n",
      "\n",
      "Sample candidates for first entity ('Saint-Joseph-de-Coleraine'):\n",
      "  1. Saint-Joseph-de-Coleraine,_Quebec (URI: http://dbpedia.org/resource/Saint-Joseph-de-Coleraine,_Quebec, ID: 10500, Language: English)\n",
      "  2. Saint-Joseph-de-Beauce (URI: http://dbpedia.org/resource/Saint-Joseph-de-Beauce, ID: 33775, Language: English)\n",
      "  3. Saint-Joseph-de-Lepage,_Quebec (URI: http://dbpedia.org/resource/Saint-Joseph-de-Lepage,_Quebec, ID: 36175, Language: English)\n",
      "  4. Saint-Valérien-de-Milton,_Quebec (URI: http://dbpedia.org/resource/Saint-Valérien-de-Milton,_Quebec, ID: 17181, Language: English)\n",
      "  5. Saint-Bernard-de-Michaudville,_Quebec (URI: http://dbpedia.org/resource/Saint-Bernard-de-Michaudville,_Quebec, ID: 20105, Language: English)\n"
     ]
    }
   ],
   "source": [
    "# Create the enhanced dataframe with entity names and URIs\n",
    "entity_alignment_data = []\n",
    "\n",
    "print(\"Creating enhanced dataframe with entity names and URIs...\")\n",
    "for _, row in df.iterrows():\n",
    "    index_id = row['index']\n",
    "    candidates = row['candidates']\n",
    "    \n",
    "    # Get index entity information (from KG1 - French)\n",
    "    if index_id in kg1_mappings:\n",
    "        index_name = kg1_mappings[index_id]['name']\n",
    "        index_uri = kg1_mappings[index_id]['uri']\n",
    "        index_language = 'French'\n",
    "    else:\n",
    "        index_name = f\"Unknown_Entity_{index_id}\"\n",
    "        index_uri = f\"Unknown_URI_{index_id}\"\n",
    "        index_language = 'Unknown'\n",
    "    \n",
    "    # Get candidate entities information (from KG2 - English)\n",
    "    candidate_info = []\n",
    "    for candidate_id in candidates:\n",
    "        if candidate_id in kg2_mappings:\n",
    "            candidate_name = kg2_mappings[candidate_id]['name']\n",
    "            candidate_uri = kg2_mappings[candidate_id]['uri']\n",
    "            candidate_language = 'English'\n",
    "        else:\n",
    "            candidate_name = f\"Unknown_Entity_{candidate_id}\"\n",
    "            candidate_uri = f\"Unknown_URI_{candidate_id}\"\n",
    "            candidate_language = 'Unknown'\n",
    "        \n",
    "        candidate_info.append([candidate_name, candidate_uri, candidate_id, candidate_language])\n",
    "    \n",
    "    # Create the row structure: [index_name, index_uri, index_id, language, candidates_list]\n",
    "    entity_alignment_data.append({\n",
    "        'index_name': index_name,\n",
    "        'index_uri': index_uri,\n",
    "        'index_id': index_id,\n",
    "        'index_language': index_language,\n",
    "        'candidates': candidate_info,\n",
    "        'num_candidates': len(candidate_info)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "enhanced_df = pd.DataFrame(entity_alignment_data)\n",
    "\n",
    "print(f\"Enhanced DataFrame shape: {enhanced_df.shape}\")\n",
    "print(\"\\nFirst few rows of enhanced DataFrame:\")\n",
    "print(enhanced_df[['index_name', 'index_uri', 'index_id', 'index_language', 'num_candidates']].head())\n",
    "\n",
    "# Show a sample of candidates for the first entity\n",
    "print(f\"\\nSample candidates for first entity ('{enhanced_df.iloc[0]['index_name']}'):\")\n",
    "for i, candidate in enumerate(enhanced_df.iloc[0]['candidates'][:5]):  # Show first 5 candidates\n",
    "    print(f\"  {i+1}. {candidate[0]} (URI: {candidate[1]}, ID: {candidate[2]}, Language: {candidate[3]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced dataframe saved to: processed_data/entity_alignment_with_names_and_uris.csv\n",
      "Flattened dataframe saved to: processed_data/entity_alignment_flattened_with_uris.csv\n",
      "Flattened DataFrame shape: (90000, 8)\n",
      "\n",
      "First few rows of flattened DataFrame:\n",
      "                  index_name  \\\n",
      "0  Saint-Joseph-de-Coleraine   \n",
      "1  Saint-Joseph-de-Coleraine   \n",
      "2  Saint-Joseph-de-Coleraine   \n",
      "3  Saint-Joseph-de-Coleraine   \n",
      "4  Saint-Joseph-de-Coleraine   \n",
      "5  Saint-Joseph-de-Coleraine   \n",
      "6  Saint-Joseph-de-Coleraine   \n",
      "7  Saint-Joseph-de-Coleraine   \n",
      "8  Saint-Joseph-de-Coleraine   \n",
      "9  Saint-Joseph-de-Coleraine   \n",
      "\n",
      "                                           index_uri  index_id index_language  \\\n",
      "0  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "1  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "2  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "3  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "4  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "5  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "6  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "7  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "8  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "9  http://fr.dbpedia.org/resource/Saint-Joseph-de...         0         French   \n",
      "\n",
      "                          candidate_name  \\\n",
      "0      Saint-Joseph-de-Coleraine,_Quebec   \n",
      "1                 Saint-Joseph-de-Beauce   \n",
      "2         Saint-Joseph-de-Lepage,_Quebec   \n",
      "3       Saint-Valérien-de-Milton,_Quebec   \n",
      "4  Saint-Bernard-de-Michaudville,_Quebec   \n",
      "5     Saint-Joseph-de-Kamouraska,_Quebec   \n",
      "6         Saint-Paul-de-Montminy,_Quebec   \n",
      "7       Saint-Isidore-de-Clifton,_Quebec   \n",
      "8         Saint-Paul-de-la-Croix,_Quebec   \n",
      "9               Saint-Edmond-de-Grantham   \n",
      "\n",
      "                                       candidate_uri  candidate_id  \\\n",
      "0  http://dbpedia.org/resource/Saint-Joseph-de-Co...         10500   \n",
      "1  http://dbpedia.org/resource/Saint-Joseph-de-Be...         33775   \n",
      "2  http://dbpedia.org/resource/Saint-Joseph-de-Le...         36175   \n",
      "3  http://dbpedia.org/resource/Saint-Valérien-de-...         17181   \n",
      "4  http://dbpedia.org/resource/Saint-Bernard-de-M...         20105   \n",
      "5  http://dbpedia.org/resource/Saint-Joseph-de-Ka...         32176   \n",
      "6  http://dbpedia.org/resource/Saint-Paul-de-Mont...         11787   \n",
      "7  http://dbpedia.org/resource/Saint-Isidore-de-C...         38085   \n",
      "8  http://dbpedia.org/resource/Saint-Paul-de-la-C...         37257   \n",
      "9  http://dbpedia.org/resource/Saint-Edmond-de-Gr...         33904   \n",
      "\n",
      "  candidate_language  \n",
      "0            English  \n",
      "1            English  \n",
      "2            English  \n",
      "3            English  \n",
      "4            English  \n",
      "5            English  \n",
      "6            English  \n",
      "7            English  \n",
      "8            English  \n",
      "9            English  \n"
     ]
    }
   ],
   "source": [
    "# Save the enhanced dataframe to CSV\n",
    "csv_file_path = 'processed_data/entity_alignment_with_names_and_uris.csv'\n",
    "\n",
    "# For CSV export, we need to convert the candidates list to a string format\n",
    "# that can be properly saved and loaded later\n",
    "enhanced_df_for_csv = enhanced_df.copy()\n",
    "enhanced_df_for_csv['candidates_str'] = enhanced_df_for_csv['candidates'].apply(str)\n",
    "\n",
    "# Save the main columns (excluding the original candidates list which is complex)\n",
    "columns_to_save = ['index_name', 'index_uri', 'index_id', 'index_language', 'candidates_str', 'num_candidates']\n",
    "enhanced_df_for_csv[columns_to_save].to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Enhanced dataframe saved to: {csv_file_path}\")\n",
    "\n",
    "# Also create a more readable version where each candidate is on a separate row\n",
    "flattened_data = []\n",
    "for _, row in enhanced_df.iterrows():\n",
    "    index_name = row['index_name']\n",
    "    index_uri = row['index_uri']\n",
    "    index_id = row['index_id']\n",
    "    index_language = row['index_language']\n",
    "    \n",
    "    for candidate in row['candidates']:\n",
    "        candidate_name, candidate_uri, candidate_id, candidate_language = candidate\n",
    "        flattened_data.append({\n",
    "            'index_name': index_name,\n",
    "            'index_uri': index_uri,\n",
    "            'index_id': index_id,\n",
    "            'index_language': index_language,\n",
    "            'candidate_name': candidate_name,\n",
    "            'candidate_uri': candidate_uri,\n",
    "            'candidate_id': candidate_id,\n",
    "            'candidate_language': candidate_language\n",
    "        })\n",
    "\n",
    "flattened_df = pd.DataFrame(flattened_data)\n",
    "flattened_csv_path = 'processed_data/entity_alignment_flattened_with_uris.csv'\n",
    "flattened_df.to_csv(flattened_csv_path, index=False)\n",
    "\n",
    "print(f\"Flattened dataframe saved to: {flattened_csv_path}\")\n",
    "print(f\"Flattened DataFrame shape: {flattened_df.shape}\")\n",
    "print(\"\\nFirst few rows of flattened DataFrame:\")\n",
    "print(flattened_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY STATISTICS ===\n",
      "Total number of index entities (French): 4500\n",
      "Total number of candidate pairs: 90000\n",
      "Average candidates per index entity: 20.00\n",
      "\n",
      "Unknown entities:\n",
      "  - Unknown index entities: 0\n",
      "  - Unknown candidate entities: 0\n",
      "\n",
      "Files created in 'processed_data' folder:\n",
      "  1. entity_alignment_with_names_and_uris.csv - Main dataframe with candidates as string\n",
      "  2. entity_alignment_flattened_with_uris.csv - Each index-candidate pair as separate row\n",
      "\n",
      "=== SAMPLE DATA STRUCTURE ===\n",
      "Format: [entity_name, entity_uri, entity_id, language] [[candidate_1_name, candidate_1_uri, candidate_1_id, language], ...]\n",
      "Example:\n",
      "['Saint-Joseph-de-Coleraine', 'http://fr.dbpedia.org/resource/Saint-Joseph-de-Coleraine', 0, 'French']\n",
      "Candidates: [['Saint-Joseph-de-Coleraine,_Quebec', 'http://dbpedia.org/resource/Saint-Joseph-de-Coleraine,_Quebec', 10500, 'English'], ['Saint-Joseph-de-Beauce', 'http://dbpedia.org/resource/Saint-Joseph-de-Beauce', 33775, 'English']]...\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"=== SUMMARY STATISTICS ===\")\n",
    "print(f\"Total number of index entities (French): {len(enhanced_df)}\")\n",
    "print(f\"Total number of candidate pairs: {len(flattened_df)}\")\n",
    "print(f\"Average candidates per index entity: {flattened_df.shape[0] / enhanced_df.shape[0]:.2f}\")\n",
    "\n",
    "# Check for any unknown entities\n",
    "unknown_index = enhanced_df[enhanced_df['index_language'] == 'Unknown'].shape[0]\n",
    "unknown_candidates = flattened_df[flattened_df['candidate_language'] == 'Unknown'].shape[0]\n",
    "\n",
    "print(f\"\\nUnknown entities:\")\n",
    "print(f\"  - Unknown index entities: {unknown_index}\")\n",
    "print(f\"  - Unknown candidate entities: {unknown_candidates}\")\n",
    "\n",
    "print(f\"\\nFiles created in 'processed_data' folder:\")\n",
    "print(f\"  1. entity_alignment_with_names_and_uris.csv - Main dataframe with candidates as string\")\n",
    "print(f\"  2. entity_alignment_flattened_with_uris.csv - Each index-candidate pair as separate row\")\n",
    "\n",
    "# Show sample of the data structure requested\n",
    "print(f\"\\n=== SAMPLE DATA STRUCTURE ===\")\n",
    "sample_entity = enhanced_df.iloc[0]\n",
    "print(f\"Format: [entity_name, entity_uri, entity_id, language] [[candidate_1_name, candidate_1_uri, candidate_1_id, language], ...]\")\n",
    "print(f\"Example:\")\n",
    "print(f\"['{sample_entity['index_name']}', '{sample_entity['index_uri']}', {sample_entity['index_id']}, '{sample_entity['index_language']}']\")\n",
    "print(f\"Candidates: {sample_entity['candidates'][:2]}...\")  # Show first 2 candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
